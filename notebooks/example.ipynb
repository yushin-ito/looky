{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "863d26af",
   "metadata": {},
   "source": [
    "# Virtual Try On using Looky\n",
    "\n",
    "This notebook demonstrates how to virtual try-on using Looky.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a84742",
   "metadata": {},
   "source": [
    "## Import libraries\n",
    "\n",
    "Run the cells below to import the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dc8a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from time import sleep\n",
    "from typing import Tuple\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import supervision as sv\n",
    "from dask.distributed import Client\n",
    "from dask_jobqueue import PBSCluster\n",
    "from PIL import Image\n",
    "from skimage.morphology import remove_small_objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73e8f77",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "## Initialize cluster\n",
    "\n",
    "Run the cells below to initialize cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c020fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = subprocess.check_output(\"hostname -I\", shell=True).decode().split()\n",
    "\n",
    "cluster = PBSCluster(\n",
    "    queue=\"gen_S\",\n",
    "    account=\"LOOKY\",\n",
    "    cores=48,\n",
    "    memory=\"96GB\",\n",
    "    processes=1,\n",
    "    job_directives_skip=[\"select=\", \"walltime=\"],\n",
    "    job_extra_directives=[\n",
    "        \"-V\",\n",
    "        \"-l elapstim_req=00:30:00\",\n",
    "        \"-T openmpi\",\n",
    "        \"-v NQSV_MPI_VER=4.1.8/gcc11.4.0-cuda12.8.1\",\n",
    "    ],\n",
    "    scheduler_options={\"host\": parts[0]},\n",
    "    env_extra=[\n",
    "        \"cd $PBS_O_WORKDIR/..\",\n",
    "        \"export HF_HUB_OFFLINE=1\",\n",
    "        \"export HF_DATASETS_OFFLINE=1\",\n",
    "        \"export TRANSFORMERS_OFFLINE=1\",\n",
    "    ],\n",
    "    interface=\"eno1\",\n",
    ")\n",
    "\n",
    "cluster.scale(jobs=1)\n",
    "sleep(10)\n",
    "\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dbdcc5",
   "metadata": {},
   "source": [
    "## Define functions\n",
    "\n",
    "Run the cells below to define functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605d6c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from transformers.models.detr.image_processing_detr.masks_to_boxes\n",
    "def masks_to_boxes(masks: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute the bounding boxes around the provided panoptic segmentation masks.\n",
    "\n",
    "    Args:\n",
    "        masks: masks in format `[number_masks, height, width]` where N is the number of masks\n",
    "\n",
    "    Returns:\n",
    "        boxes: bounding boxes in format `[number_masks, 4]` in xyxy format\n",
    "    \"\"\"\n",
    "    if masks.size == 0:\n",
    "        return np.zeros((0, 4))\n",
    "\n",
    "    h, w = masks.shape[-2:]\n",
    "    y = np.arange(0, h, dtype=np.float32)\n",
    "    x = np.arange(0, w, dtype=np.float32)\n",
    "    # see https://github.com/pytorch/pytorch/issues/50276\n",
    "    y, x = np.meshgrid(y, x, indexing=\"ij\")\n",
    "\n",
    "    x_mask = masks * np.expand_dims(x, axis=0)\n",
    "    x_max = x_mask.reshape(x_mask.shape[0], -1).max(-1)\n",
    "    x = np.ma.array(x_mask, mask=~(np.array(masks, dtype=bool)))\n",
    "    x_min = x.filled(fill_value=1e8)\n",
    "    x_min = x_min.reshape(x_min.shape[0], -1).min(-1)\n",
    "\n",
    "    y_mask = masks * np.expand_dims(y, axis=0)\n",
    "    y_max = y_mask.reshape(x_mask.shape[0], -1).max(-1)\n",
    "    y = np.ma.array(y_mask, mask=~(np.array(masks, dtype=bool)))\n",
    "    y_min = y.filled(fill_value=1e8)\n",
    "    y_min = y_min.reshape(y_min.shape[0], -1).min(-1)\n",
    "\n",
    "    return np.stack([x_min, y_min, x_max, y_max], 1)\n",
    "\n",
    "\n",
    "def get_upper_body_mask(\n",
    "    segmentation: np.ndarray,\n",
    "    keypoints: np.ndarray,\n",
    "    scores: np.ndarray,\n",
    "    target_size: Tuple[int, int],\n",
    "):\n",
    "    height, width = target_size\n",
    "\n",
    "    keypoints = keypoints.copy()\n",
    "    keypoints[..., 0] *= width\n",
    "    keypoints[..., 1] *= height\n",
    "\n",
    "    face_keypoints = keypoints[24:92]\n",
    "    face_scores = scores[24:92]\n",
    "\n",
    "    right_hand_keypoints = keypoints[92:113]\n",
    "    right_hand_scores = scores[92:113]\n",
    "\n",
    "    left_hand_keypoints = keypoints[113:]\n",
    "    left_hand_scores = scores[113:]\n",
    "\n",
    "    body_keypoints = keypoints[:18]\n",
    "    body_scores = scores[:18]\n",
    "\n",
    "    # upper-clothes / dress / coat\n",
    "    mask = np.isin(segmentation, [5, 6, 7])\n",
    "    mask = remove_small_objects(mask, min_size=300)\n",
    "    boxes = masks_to_boxes(mask[None, ...])\n",
    "    box1 = boxes[0]\n",
    "\n",
    "    x_min = float(\"inf\")\n",
    "    y_min = float(\"inf\")\n",
    "    x_max = float(\"-inf\")\n",
    "    y_max = float(\"-inf\")\n",
    "\n",
    "    for i in [2, 3, 4]:\n",
    "        if body_scores[i] > 0.3:\n",
    "            x = body_keypoints[i, 0]\n",
    "            x_min = min(x_min, x)\n",
    "\n",
    "    for i in [2, 5]:\n",
    "        if body_scores[i] > 0.3:\n",
    "            y = body_keypoints[i, 1]\n",
    "            y_min = min(y_min, y)\n",
    "\n",
    "    for i in [5, 6, 7]:\n",
    "        if body_scores[i] > 0.3:\n",
    "            x = body_keypoints[i, 0]\n",
    "            x_max = max(x_max, x)\n",
    "\n",
    "    for i in [8, 11]:\n",
    "        if body_scores[i] > 0.3:\n",
    "            y = body_keypoints[i, 1]\n",
    "            y_max = max(y_max, y)\n",
    "\n",
    "    for i in [5, 9, 13]:\n",
    "        if left_hand_scores[i] > 0.3:\n",
    "            x = left_hand_keypoints[i, 0]\n",
    "            y = left_hand_keypoints[i, 1]\n",
    "\n",
    "            x_min = min(x_min, x)\n",
    "            y_min = min(y_min, y)\n",
    "            x_max = max(x_max, x)\n",
    "            y_max = max(y_max, y)\n",
    "\n",
    "        if right_hand_scores[i] > 0.3:\n",
    "            x = right_hand_keypoints[i, 0]\n",
    "            y = right_hand_keypoints[i, 1]\n",
    "\n",
    "            x_min = min(x_min, x)\n",
    "            y_min = min(y_min, y)\n",
    "            x_max = max(x_max, x)\n",
    "            y_max = max(y_max, y)\n",
    "\n",
    "    for i in [5, 11]:\n",
    "        if face_scores[i] > 0.3:\n",
    "            y = face_keypoints[i, 1]\n",
    "            y_min = min(y_min, y)\n",
    "\n",
    "    box2 = [x_min, y_min, x_max, y_max]\n",
    "\n",
    "    x_min = min(box1[0], box2[0])\n",
    "    y_min = min(box1[1], box2[1])\n",
    "    x_max = max(box1[2], box2[2])\n",
    "    y_max = max(box1[3], box2[3])\n",
    "\n",
    "    x_min = max(0, x_min - 20)\n",
    "    y_min = max(0, y_min - 10)\n",
    "    x_max = min(width, x_max + 25)\n",
    "    if box2[3] > box1[3]:\n",
    "        y_max = min(height, y_max)\n",
    "    else:\n",
    "        y_max = min(height, y_max + 25)\n",
    "\n",
    "    x_min = int(x_min)\n",
    "    y_min = int(y_min)\n",
    "    x_max = int(x_max)\n",
    "    y_max = int(y_max)\n",
    "\n",
    "    agnostic_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "    agnostic_mask[y_min:y_max, x_min:x_max] = 255\n",
    "\n",
    "    # hat / hair / sunglasses / face\n",
    "    mask = np.isin(segmentation, [1, 2, 4, 13])\n",
    "    agnostic_mask[mask] = 0\n",
    "\n",
    "    agnostic_mask = Image.fromarray(agnostic_mask)\n",
    "    boxes = np.array([box1, box2])\n",
    "\n",
    "    return agnostic_mask, boxes\n",
    "\n",
    "\n",
    "def get_lower_body_mask(\n",
    "    segmentation,\n",
    "    keypoints,\n",
    "    scores,\n",
    "    target_size,\n",
    "):\n",
    "    height, width = target_size\n",
    "\n",
    "    keypoints = keypoints.copy()\n",
    "    keypoints[..., 0] *= width\n",
    "    keypoints[..., 1] *= height\n",
    "\n",
    "    body_keypoints = keypoints[:18]\n",
    "    body_scores = scores[:18]\n",
    "\n",
    "    right_foot_keypoints = keypoints[18:21]\n",
    "    right_foot_scores = scores[18:21]\n",
    "\n",
    "    left_foot_keypoints = keypoints[21:24]\n",
    "    left_foot_scores = scores[21:24]\n",
    "\n",
    "    # skirt / pants / dress / belt\n",
    "    mask = np.isin(segmentation, [6, 9, 12])\n",
    "    mask = remove_small_objects(mask, min_size=300)\n",
    "    boxes = masks_to_boxes(mask[None, ...])\n",
    "    box1 = boxes[0]\n",
    "\n",
    "    x_min = float(\"inf\")\n",
    "    y_min = float(\"inf\")\n",
    "    x_max = float(\"-inf\")\n",
    "    y_max = float(\"-inf\")\n",
    "\n",
    "    for i in [8, 9, 10, 11, 12, 13]:\n",
    "        if body_scores[i] > 0.3:\n",
    "            x = body_keypoints[i, 0]\n",
    "            x_min = min(x_min, x)\n",
    "            x_max = max(x_max, x)\n",
    "\n",
    "    for i in [8, 11]:\n",
    "        if body_scores[i] > 0.3:\n",
    "            y = body_keypoints[i, 1]\n",
    "            y_min = min(y_min, y)\n",
    "\n",
    "    for i in [10, 13]:\n",
    "        if body_scores[i] > 0.3:\n",
    "            y = body_keypoints[i, 1]\n",
    "            y_max = max(y_max, y)\n",
    "\n",
    "    for i in [0, 1, 2]:\n",
    "        if right_foot_scores[i] > 0.3:\n",
    "            x = right_foot_keypoints[i, 0]\n",
    "\n",
    "            x_min = min(x_min, x)\n",
    "            x_max = max(x_max, x)\n",
    "\n",
    "        if left_foot_scores[i] > 0.3:\n",
    "            x = left_foot_keypoints[i, 0]\n",
    "\n",
    "            x_min = min(x_min, x)\n",
    "            x_max = max(x_max, x)\n",
    "\n",
    "    for i in [2]:\n",
    "        if right_foot_scores[i] > 0.3:\n",
    "            y = right_foot_keypoints[i, 1]\n",
    "            y_max = max(y_max, y)\n",
    "\n",
    "        if left_foot_scores[i] > 0.3:\n",
    "            y = left_foot_keypoints[i, 1]\n",
    "            y_max = max(y_max, y)\n",
    "\n",
    "    box2 = [x_min, y_min, x_max, y_max]\n",
    "\n",
    "    x_min = min(box1[0], box2[0])\n",
    "    y_min = min(box1[1], box2[1])\n",
    "    x_max = max(box1[2], box2[2])\n",
    "    y_max = max(box1[3], box2[3])\n",
    "\n",
    "    x_min = max(0, x_min - 30)\n",
    "    if box2[1] > box1[1]:\n",
    "        y_min = max(0, y_min - 50)\n",
    "    else:\n",
    "        y_min = max(0, y_min - 5)\n",
    "    x_max = min(width, x_max + 30)\n",
    "    y_max = min(height, y_max + 10)\n",
    "\n",
    "    x_min = int(x_min)\n",
    "    y_min = int(y_min)\n",
    "    x_max = int(x_max)\n",
    "    y_max = int(y_max)\n",
    "\n",
    "    agnostic_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "    agnostic_mask[y_min:y_max, x_min:x_max] = 255\n",
    "\n",
    "    # left-shoe / right-shoe\n",
    "    mask = np.isin(segmentation, [18, 19])\n",
    "    agnostic_mask[mask] = 0\n",
    "\n",
    "    agnostic_mask = Image.fromarray(agnostic_mask)\n",
    "    boxes = np.array([box1, box2])\n",
    "\n",
    "    return agnostic_mask, boxes\n",
    "\n",
    "\n",
    "def get_full_body_mask(\n",
    "    segmentation: np.ndarray,\n",
    "    keypoints: np.ndarray,\n",
    "    scores: np.ndarray,\n",
    "    target_size: Tuple[int, int],\n",
    "):\n",
    "    height, width = target_size\n",
    "\n",
    "    keypoints = keypoints.copy()\n",
    "    keypoints[..., 0] *= width\n",
    "    keypoints[..., 1] *= height\n",
    "\n",
    "    face_keypoints = keypoints[24:92]\n",
    "    face_scores = scores[24:92]\n",
    "\n",
    "    right_hand_keypoints = keypoints[92:113]\n",
    "    right_hand_scores = scores[92:113]\n",
    "\n",
    "    left_hand_keypoints = keypoints[113:]\n",
    "    left_hand_scores = scores[113:]\n",
    "\n",
    "    body_keypoints = keypoints[:18]\n",
    "    body_scores = scores[:18]\n",
    "\n",
    "    right_foot_keypoints = keypoints[18:21]\n",
    "    right_foot_scores = scores[18:21]\n",
    "\n",
    "    left_foot_keypoints = keypoints[21:24]\n",
    "    left_foot_scores = scores[21:24]\n",
    "\n",
    "    # upper-clothes / dress / coat / skirt / pants / belt\n",
    "    mask = np.isin(segmentation, [5, 6, 7, 9, 12])\n",
    "    mask = remove_small_objects(mask, min_size=300)\n",
    "    boxes = masks_to_boxes(mask[None, ...])\n",
    "    box1 = boxes[0]\n",
    "\n",
    "    x_min = float(\"inf\")\n",
    "    y_min = float(\"inf\")\n",
    "    x_max = float(\"-inf\")\n",
    "    y_max = float(\"-inf\")\n",
    "\n",
    "    for i in [2, 3, 4, 8, 9, 10]:\n",
    "        if body_scores[i] > 0.3:\n",
    "            x = body_keypoints[i, 0]\n",
    "            x_min = min(x_min, x)\n",
    "\n",
    "    for i in [5, 6, 7, 11, 12, 13]:\n",
    "        if body_scores[i] > 0.3:\n",
    "            x = body_keypoints[i, 0]\n",
    "            x_max = max(x_max, x)\n",
    "\n",
    "    for i in [2, 5]:\n",
    "        if body_scores[i] > 0.3:\n",
    "            y = body_keypoints[i, 1]\n",
    "            y_min = min(y_min, y)\n",
    "\n",
    "    for i in [10, 13]:\n",
    "        if body_scores[i] > 0.3:\n",
    "            y = body_keypoints[i, 1]\n",
    "            y_max = max(y_max, y)\n",
    "\n",
    "    for i in [5, 9, 13, 17]:\n",
    "        if right_hand_scores[i] > 0.3:\n",
    "            x = right_hand_keypoints[i, 0]\n",
    "            y = right_hand_keypoints[i, 1]\n",
    "\n",
    "            x_min = min(x_min, x)\n",
    "            y_min = min(y_min, y)\n",
    "\n",
    "        if left_hand_scores[i] > 0.3:\n",
    "            x = left_hand_keypoints[i, 0]\n",
    "            y = left_hand_keypoints[i, 1]\n",
    "\n",
    "            x_max = max(x_max, x)\n",
    "            y_min = min(y_min, y)\n",
    "\n",
    "    for i in [0, 1, 2]:\n",
    "        if right_foot_scores[i] > 0.3:\n",
    "            x = right_foot_keypoints[i, 0]\n",
    "            y = right_foot_keypoints[i, 1]\n",
    "\n",
    "            x_max = max(x_max, x)\n",
    "            y_max = max(y_max, y)\n",
    "\n",
    "        if left_foot_scores[i] > 0.3:\n",
    "            x = left_foot_keypoints[i, 0]\n",
    "            y = left_foot_keypoints[i, 1]\n",
    "\n",
    "            x_min = min(x_min, x)\n",
    "            y_max = max(y_max, y)\n",
    "\n",
    "    for i in [5, 11]:\n",
    "        if face_scores[i] > 0.3:\n",
    "            y = face_keypoints[i, 1]\n",
    "            y_min = min(y_min, y)\n",
    "\n",
    "    box2 = [x_min, y_min, x_max, y_max]\n",
    "\n",
    "    x_min = min(box1[0], box2[0])\n",
    "    y_min = min(box1[1], box2[1])\n",
    "    x_max = max(box1[2], box2[2])\n",
    "    y_max = max(box1[3], box2[3])\n",
    "\n",
    "    x_min = max(0, x_min - 50)\n",
    "    if box2[1] > box1[1]:\n",
    "        y_min = max(0, y_min - 20)\n",
    "    else:\n",
    "        y_min = max(0, y_min)\n",
    "    x_max = min(width, x_max + 50)\n",
    "    y_max = min(height, y_max + 10)\n",
    "\n",
    "    x_min = int(x_min)\n",
    "    y_min = int(y_min)\n",
    "    x_max = int(x_max)\n",
    "    y_max = int(y_max)\n",
    "\n",
    "    agnostic_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "    agnostic_mask[y_min:y_max, x_min:x_max] = 255\n",
    "\n",
    "    # hat / hair / sunglasses / face / left-shoe / right-shoe\n",
    "    mask = np.isin(segmentation, [1, 2, 4, 13, 18, 19])\n",
    "    agnostic_mask[mask] = 0\n",
    "\n",
    "    agnostic_mask = Image.fromarray(agnostic_mask)\n",
    "    boxes = np.array([box1, box2])\n",
    "\n",
    "    return agnostic_mask, boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f34049a",
   "metadata": {},
   "source": [
    "## Visualize images\n",
    "\n",
    "Run the cells below to visualize images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a4af37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 000001 / 003940 / 007427\n",
    "image = Image.open(\"../data/test/person/007427.jpg\").convert(\"RGB\")\n",
    "garment_image = Image.open(\"../data/test/garment/007427.jpg\").convert(\"RGB\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Person\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(garment_image)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Garment\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79974725",
   "metadata": {},
   "source": [
    "## Estimate pose\n",
    "\n",
    "Run the cells below to estimate pose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899a988b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(image):\n",
    "    from accelerate import Accelerator\n",
    "    from looky.dwpose import DWposeDetector\n",
    "\n",
    "    device = Accelerator().device\n",
    "\n",
    "    detector = DWposeDetector(device=device)\n",
    "\n",
    "    pose_image, keypoints, scores = detector(image)\n",
    "\n",
    "    return pose_image, keypoints, scores\n",
    "\n",
    "\n",
    "future = client.submit(func, image)\n",
    "pose_image, keypoints, scores = future.result()\n",
    "\n",
    "keypoints = keypoints[0]\n",
    "scores = scores[0]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(pose_image)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0619aa31",
   "metadata": {},
   "source": [
    "## Parse human \n",
    "\n",
    "Run the cells below to parse human."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc3a397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(image):\n",
    "    import torch\n",
    "    from accelerate import Accelerator\n",
    "    from transformers import AutoImageProcessor, Mask2FormerForUniversalSegmentation\n",
    "\n",
    "    device = Accelerator().device\n",
    "\n",
    "    image_processor = AutoImageProcessor.from_pretrained(\n",
    "        \"./weights/human_parsing\",\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        local_files_only=True,\n",
    "    )\n",
    "    model = Mask2FormerForUniversalSegmentation.from_pretrained(\n",
    "        \"./weights/human_parsing\", local_files_only=True\n",
    "    )\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    inputs = image_processor(image, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    outputs = image_processor.post_process_semantic_segmentation(\n",
    "        outputs, target_sizes=[(image.height, image.width)]\n",
    "    )[0]\n",
    "\n",
    "    segmentation = outputs.cpu().numpy()\n",
    "\n",
    "    return segmentation\n",
    "\n",
    "\n",
    "future = client.submit(func, image)\n",
    "segmentation = future.result()\n",
    "\n",
    "all_labels = np.unique(segmentation)\n",
    "\n",
    "boxes = []\n",
    "masks = []\n",
    "class_ids = []\n",
    "\n",
    "for label in all_labels:\n",
    "    if label == 0:\n",
    "        continue\n",
    "\n",
    "    mask = (segmentation == label).astype(np.uint8) * 255\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area < 300:\n",
    "            continue\n",
    "\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        box = [x, y, x + w, y + h]\n",
    "\n",
    "        boxes.append(box)\n",
    "        mask = np.zeros_like(segmentation, dtype=np.uint8)\n",
    "        cv2.drawContours(mask, [contour], -1, 255, thickness=-1)\n",
    "        mask = mask.astype(bool)\n",
    "\n",
    "        masks.append(mask)\n",
    "        class_ids.append(label)\n",
    "\n",
    "detections = sv.Detections(\n",
    "    xyxy=np.array(boxes),\n",
    "    mask=np.stack(masks),\n",
    "    class_id=np.array(class_ids),\n",
    ")\n",
    "\n",
    "mask_annotator = sv.MaskAnnotator()\n",
    "label_annotator = sv.LabelAnnotator(text_position=sv.Position.BOTTOM_RIGHT)\n",
    "\n",
    "id2label = {\n",
    "    0: \"background\",\n",
    "    1: \"hat\",\n",
    "    2: \"hair\",\n",
    "    3: \"glove\",\n",
    "    4: \"sunglasses\",\n",
    "    5: \"upper-clothes\",\n",
    "    6: \"dress\",\n",
    "    7: \"coat\",\n",
    "    8: \"socks\",\n",
    "    9: \"pants\",\n",
    "    10: \"torso-skin\",\n",
    "    11: \"scarf\",\n",
    "    12: \"skirt\",\n",
    "    13: \"face\",\n",
    "    14: \"left-arm\",\n",
    "    15: \"right-arm\",\n",
    "    16: \"left-leg\",\n",
    "    17: \"right-leg\",\n",
    "    18: \"left-shoe\",\n",
    "    19: \"right-shoe\",\n",
    "}\n",
    "\n",
    "labels = []\n",
    "for class_id in detections.class_id:\n",
    "    label = id2label[class_id]\n",
    "    labels.append(label)\n",
    "\n",
    "annotated_image = mask_annotator.annotate(image.copy(), detections)\n",
    "annotated_image = label_annotator.annotate(\n",
    "    annotated_image,\n",
    "    detections,\n",
    "    labels=labels,\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(annotated_image)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c87628",
   "metadata": {},
   "source": [
    "## Generate mask\n",
    "\n",
    "Run the cells below to generate mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a0e753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upper-bdoy / lower-body / full-body\n",
    "category = \"full-body\"\n",
    "\n",
    "width, height = image.size\n",
    "target_size = (height, width)\n",
    "\n",
    "if category == \"upper-body\":\n",
    "    agnostic_mask, boxes = get_upper_body_mask(\n",
    "        segmentation, keypoints, scores, target_size\n",
    "    )\n",
    "if category == \"lower-body\":\n",
    "    agnostic_mask, boxes = get_lower_body_mask(\n",
    "        segmentation, keypoints, scores, target_size\n",
    "    )\n",
    "if category == \"full-body\":\n",
    "    agnostic_mask, boxes = get_full_body_mask(\n",
    "        segmentation, keypoints, scores, target_size\n",
    "    )\n",
    "\n",
    "detections = sv.Detections(\n",
    "    xyxy=boxes,\n",
    "    class_id=np.array([0, 1]),\n",
    ")\n",
    "\n",
    "box_annotator = sv.BoxAnnotator()\n",
    "\n",
    "annotated_image = box_annotator.annotate(\n",
    "    scene=image.copy(),\n",
    "    detections=detections,\n",
    ")\n",
    "\n",
    "masked_image = image.copy()\n",
    "masked_image.paste(Image.new(\"RGB\", image.size, \"gray\"), mask=agnostic_mask)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(annotated_image)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(masked_image)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6246ee13",
   "metadata": {},
   "source": [
    "## Inference mask\n",
    "\n",
    "Run the cells below to try on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304fe84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(image, mask_image, garment_image, pose_image):\n",
    "    import torch\n",
    "    from accelerate import Accelerator\n",
    "\n",
    "    from looky.pipelines.pipeline_virtual_try_on import VirtualTryOnPipeline\n",
    "\n",
    "    device = Accelerator().device\n",
    "\n",
    "    pipe = VirtualTryOnPipeline.from_pretrained(\n",
    "        \"./weights/virtual_try_on\",\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        local_files_only=True,\n",
    "    )\n",
    "    pipe.to(device)\n",
    "\n",
    "    images = pipe(\n",
    "        image=image,\n",
    "        mask_image=mask_image,\n",
    "        garment_image=garment_image,\n",
    "        pose_image=pose_image,\n",
    "        height=1024,\n",
    "        width=768,\n",
    "        num_inference_steps=20,\n",
    "        guidance_scale=2.0,\n",
    "    ).images\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "future = client.submit(\n",
    "    func,\n",
    "    image,\n",
    "    agnostic_mask,\n",
    "    garment_image,\n",
    "    pose_image,\n",
    ")\n",
    "images = future.result()\n",
    "generated_image = images[0]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(generated_image)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "looky",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
